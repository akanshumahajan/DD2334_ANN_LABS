Plots generated by averaging over 200 different data generations and data fittings. The average MSE and miss error calculated over 200 runs.

We observe that the MSE and number of miss are similar. Just studying one of them suffices. After 100 epochs it is clear that 1 neuron in the hidden layer is note enough. But 10 neurons and above are pose too many parameters for the network to learn properly. Initially the higher the number of neurons the larger the error, this is due to the fact that the first guess of the weights is more likely to be wrong given more parameters. From the plot we conclude that the most appropriate number of neurons in the hidden layer is 5.
